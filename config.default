# This is a sample configuration file for the CROWler, for a generic configuration
# that should work for most small to medium deployments. You can use this as a
# starting point for your own configuration file.

---
database:
  type: postgres
  host: "${POSTGRES_DB_HOST}"
  port: 5432
  user: "${CROWLER_DB_USER}"
  password: "${CROWLER_DB_PASSWORD}"
  dbname: SitesIndex
  sslmode: disable
  max_conns: 1000
  max_idle_conns: 100

crawler:
  source_screenshot: true
  interval: random(random(2,5), random(5,10))
  workers: 5
  delay: random(4,35)
  timeout: 10
  maintenance: 60
  collect_html: false
  collect_content: false
  collect_images: false

api:
  port: 8080
  host: 0.0.0.0
  timeout: 60
  write_timeout: 60
  readheader_timeout: 60
  rate_limit: '1010,1010'
  enable_console: true
  return_404: false

selenium:
  - name: crowler_vdi_1
    type: chrome
    path: ''
    port: 4444
    host: crowler_vdi_1
    use_service: false
    sslmode: disable

image_storage:
  type: local
  path: "/app/data/images"

network_info:
  netlookup:
    enabled: true
    timeout: 15
  dns:
    enabled: true
    timeout: 15
  whois:
    enabled: true
    timeout: 15
  service_scout:
    enabled: true
    timeout: 1200
  geo_localization:
    enabled: false
    path: ''
    timeout: 15

debug_level: 0
